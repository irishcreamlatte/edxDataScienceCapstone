---
title: "Analysis of Suicide Trends"
author: "ggh725"
output: pdf_document
geometry: margin=1in 
---

### INTRODUCTION ###

The aim of this project is to examine global trends in suicides in order to determine whether demographic variables are associated with suicide trends. The effectiveness of the developed models is assessed using the Root Mean Squared Error (RMSE). 

The Suicides dataset contains global suicide rates from 1985 to 2016, as well as demographic and socio-economic variables. For purposes of this project, the explanatory variables of interest are: sex, age, generation, population, and continent. The Suicides dataset was divided into training and test sets, both of which contain 50% of the observations. 

For the first part of this project, the features of the Suicides dataset are explored to determine possible trends in suicide rates. This is followed by the analysis section. Models were developed based on the assumption that the number of suicides ($\hat{Y}$) is a function of demographic variables ($X$), where ($X$) includes sex, age, generation, population, and continent. 

The project concludes with a summary of its findings, as well as a discussion of its limitation and possible extensions of the analysis. 


### EXPLORATORY DATA ANALYSIS ### 

In this section, the Suicides dataset is explored and analyzed in order to determine the features of the data and to detect possible trends. 

```{r loading packages, echo=TRUE}
library(tidyverse)
library(caret)
library(lubridate)
library(countrycode)
library(broom)
library(car)
library(randomForest)
library(ranger)
```

At the outset, the data should be downloaded and unzipped. The Suicides dataset can be found in Kaggle [Suicide Rates Overview 1985 to 2016](https://www.kaggle.com/russellyates88/suicide-rates-overview-1985-to-2016). 

```{r unzip, echo=TRUE}
file <- unzip("./suicide-rates-overview-1985-to-2016.zip")
suicides <- read.csv("./master.csv")
```

This is followed by an examination of the dataset. 

```{r overall structure, echo=TRUE}
glimpse(suicides)
summary(suicides)
head(suicides)
```

There are 27,820 observations with 12 variables. The dependent variable is number of suicides (suicides_no). The explanatory variables of interest are: country, sex, age, generation, and population. 

# Trends in Number of Suicides # 

```{r suicide rates trends, echo=TRUE}
summary(suicides$suicides_no) 
sd(suicides$suicides_no)  
IQR(suicides$suicides_no) 
```

The value of the mean is significantly higher than the median. This shows that there are outliers in the data. Additionally, the standard deviation is 902.05. As the variance is larger than the mean, a Quasipoisson analysis might be worth considering. 

The histograms below confirm the presence of outliers. Furthermore, the first histogram shows that the suicide numbers are heavily right skewed. Taking the log transformation of the number of suicides elicits a histogram which better illustrates the trends in the data. 

```{r histograms suicides number, echo=TRUE}
suicides %>% 
  ggplot(aes(suicides_no)) + geom_histogram() + 
    labs(title = "Suicides", x = "Suicides")

suicides %>% 
  ggplot(aes(log(suicides_no + 1))) + geom_histogram() + 
    labs(title = "Log Transformed", x = "Log(Suicides)")
```

# Trends in Suicides per Year # 

The plot below shows that there is no clear time trend in the number of suicides. 

```{r year trends, echo=TRUE}
suicides$year <- as.Date(as.character(suicides$year), format = "%Y")
suicides$year <- year(suicides$year)

suicides %>% 
  ggplot(aes(year, suicides_no)) + 
  geom_point(alpha = 0.01) + geom_smooth() + 
    labs(title = "Suicides per Year", x = "Year", 
         y = "Suicides")
```

# Trends per Country and Continent # 

```{r fix country variable name, echo=TRUE}
colnames(suicides)[1] <- "country"
names(suicides)
levels(suicides$country)
```

The country variable is coded as a factor variable with 101 levels. To make the analysis more tractable, a continent variable will be added. The models will be using the continent variable, rather than the country variable. 

```{r add continents, echo=TRUE}
suicides$continent <- countrycode(sourcevar = suicides[,"country"], 
                                  origin = "country.name", 
                                  destination = "continent")

str(suicides)

suicides$continent <- factor(suicides$continent)
levels(suicides$continent)
```

```{r trends per continent, echo=TRUE}
suicides %>% 
    group_by(continent) %>% 
    summarize(mean = mean(suicides_no), 
              median = median(suicides_no), 
              sd = sd(suicides_no), 
              n = n()) %>% 
    arrange(desc(mean))
```

Europe has the highest mean and median suicides, while Africa has the lowest. 

```{r top countries, echo=TRUE}
suicides %>% 
  group_by(country) %>% 
  summarize(total = sum(suicides_no)) %>% 
  arrange(desc(total)) %>% 
  top_n(10)  
```

The country with the highest total number of suicides is Russia, followed by the United States and Japan. 

# Trends per Sex # 

```{r total by sex, echo=TRUE}
levels(suicides$sex)

suicides %>% 
    group_by(sex) %>% 
    summarize(total = sum(suicides_no)) 
```

Males have a higher number of suicides than females. This trend can be seen in the Americas, Asia and Europe. 

```{r by sex and continent, echo=TRUE}
suicides %>% 
    group_by(year, continent, sex) %>% 
    summarize(total = sum(suicides_no)) %>% 
    ggplot(aes(year, total, color = sex)) +
    geom_point() + facet_wrap(~continent) + 
    labs(title = "Total Suicides, by Continent and Sex", 
         x = "Year", y = "Total Suicides")
```

# Trends per Age # 

```{r levels of age, echo=TRUE}
levels(suicides$age)
```

Age is encoded as a factor variable with 6 levels: 5-14 years, 15-24 years, 25-34 years, 35-54 years, 55-74 years, and 75+ years. 

```{r total by age, echo=TRUE}
suicides %>% 
    group_by(age) %>% 
    summarize(total = sum(suicides_no)) %>% 
    arrange(desc(total))
```

The highest number of total suicides are in the age groups which correspond to adults, i.e., 25-74 years. The trend that suicide rates for males are higher can also be seen in the adult age groups. 

```{r by age and sex, echo=TRUE}
suicides %>% 
    group_by(year, age, sex) %>% 
    summarize(total = sum(suicides_no)) %>% 
    ggplot(aes(year, total, color = sex)) + 
    geom_point() + facet_wrap(~ age) + 
    labs(title = "By Age and Sex", x = "Year", 
         y = "Total Suicides")
```

# Trends by Population # 

The population is also heavily right skewed. The log transformation of this variable can better show its distribution. 

```{r population histograms, echo=TRUE}
suicides %>% 
  ggplot(aes(population)) + geom_histogram() + 
  labs(title = "Population", x = "Population") 

suicides %>% 
  ggplot(aes(log(population))) + geom_histogram() + 
  labs(title = "Log Transformed Population", x = "Log(Population)")  
```

A cursory look at the data suggests that there is a positive association between population and suicide rates. 
```{r population and suicides, echo=TRUE}
suicides %>% 
    group_by(year, country) %>% 
    mutate(total_pop = sum(population), total_suicides = sum(suicides_no)) %>% 
    ggplot(aes(total_pop, total_suicides)) +
    geom_point(alpha = 0.01, position = "jitter") + 
    geom_smooth(method = "lm", se = FALSE) +
    labs(title = "Suicides and Population", 
       x = "Total Population", 
       y = "Total Suicides")
```

# Trends by Generation # 

```{r levels of generation, echo=TRUE}
levels(suicides$generation)
```

Generation is encoded as a factor variable with 6 levels: Boomers, G.I. Generation, Generation X, Generation Z, Millenials, and Silent. 

```{r by generation, echo=TRUE}
suicides %>% 
    group_by(generation) %>% 
    summarize(total = sum(suicides_no)) %>% 
    arrange(desc(total))

suicides %>% 
    group_by(year, generation, sex) %>% 
    summarize(total = sum(suicides_no)) %>% 
    ggplot(aes(year, total, color = sex)) +
    geom_line() + facet_wrap(~generation) + 
    labs(title = "Suicides by Generation and Sex",
         x = "Year", y = "Total Suicides")
```

The Boomer generation has the highest number of total suicides, followed by the Silent generation and Generation X. Even when viewed according to generations, males still have a higher number of suicides than females. 

# Trends by GDP # 

Before the trends can be analyzed, the variables must be cleaned. 

```{r fix variable names, echo=TRUE}
colnames(suicides)[10] <- "gdp_per_year"
colnames(suicides)[11] <- "gdp_per_capita"
names(suicides)
```

```{r from factor to numeric, echo=TRUE}
levels(suicides$gdp_per_year)

suicides$gdp_per_year <- gsub(",", "", suicides$gdp_per_year)
suicides$gdp_per_year <- as.numeric(suicides$gdp_per_year)
```

```{r per GDP, echo=TRUE}
suicides %>% 
  ggplot(aes(gdp_per_year, suicides_no)) + 
  geom_point(alpha = 0.5, position = "jitter") + 
  geom_smooth() + 
  labs(title = "Suicides and GDP", 
       x = "GDP per Year", 
       y = "Suicides")

suicides %>% 
  ggplot(aes(cut(gdp_per_year, breaks = 5), suicides_no)) +
  geom_boxplot() + 
  labs(title = "Suicides and GDP", 
       x = "GDP per Year (Breaks = 5)",
       y = "Suicides")
```

There is no clear trend between suicides and GDP per year. The scatterplot suggests a slightly positive association. However, the boxplot hints that this might be due mainly to outliers. 

### MODELS AND RESULTS ### 

In this section, different models are trained with the end goal of determining whether suicide rates are associated with demographic variables. 

First, the variables of interest are selected from the main dataset. 

```{r selecting variables, echo=TRUE}
suicides <- suicides %>% 
  select(suicides_no, sex, age, population, generation, continent)

colnames(suicides)[1] <- "suicides"
names(suicides)
```

Next, the training and validation sets are created. 

```{r train and test sets, echo=TRUE}
set.seed(725, sample.kind = "Rounding")

y <- suicides$suicides
test_index <- createDataPartition(y, times = 1, p = 0.5, list = FALSE)
test_set <- suicides %>% slice(test_index)
train_set <- suicides %>% slice(-test_index)
```

The RMSE function, which will be used to assess the performance of the models, is defined next. The RMSE refers to the residual mean squared error of the predicted suicide rates against the actual rates. The aim is to minimize the RMSE. 

```{r RMSE, echo=TRUE}
RMSE <- function(actual_suicides, predicted_suicides){
  sqrt(mean((actual_suicides - predicted_suicides)^2))
}

actual_suicides <- test_set$suicides
```

# Using the Mean # 

The simplest model is to predict the same number of suicides for all continents, with random variation explained by an error term: 

$$\hat{Y} = \mu + \varepsilon$$ 

The estimate that would minimize the RMSE is the average of all suicides. 

```{r mu, echo=TRUE}
mu <- mean(train_set$suicides)
mu
```

Using $mu$ to predict the suicide rates, the RMSE is 913.738. 

```{r rmse mu, echo=TRUE}
RMSE_mean <- RMSE(actual_suicides, mu)

options(pillar.sigfig = 6)
rmse_results <- tibble(Method = "Mean", 
                       RMSE = RMSE_mean)
rmse_results
```

The RMSE is quite high. It is higher than the standard deviation of the suicide rates. This ineffectiveness may be due to the presence of significant outliers in the data. 

# Linear Regression # 

The next option is to develop a linear model which predicts the number of suicides ($\hat{Y}$) based on the demographic variables ($X$), while at the same time minimizing the error. 

As there are 5 explanatory variables, the linear model is selected using the nested models approach. Under this approach, models which add a new variable are compared to each other using the analysis of variance (ANOVA) method. The ANOVA results can show whether the added term is necessary for the model. The variance inflation factor (VIF) is also examined to determine whether the additional term significantly increases the variance of the model.  

This nested model approach showed that it is not necessary to add generation as an explanatory variable. 

```{r sex and age, echo=TRUE}
fit1 <- lm(suicides ~ sex, train_set)
fit2 <- update(fit1, suicides ~ sex + age, train_set)
vif(fit2) ## to check the variance inflation ## 
anova(fit1, fit2) ## model 2's terms are necessary over model 1 

summary(fit2) ## Adj. R-squared = 0.05223
```

```{r with generation, echo=TRUE}
fit3 <- update(fit1, suicides ~ 
                 sex + age + generation, train_set)
vif(fit3) ## variance increased, for age and generation 
anova(fit2, fit3) ## model 2 over model 3, generation not necessary ## 

summary(fit3) ## Adj. R-squared = 0.05241 ## 
```

```{r with population, echo = TRUE}
fit4 <- update(fit1, suicides ~ 
                   sex + age + 
                   population, train_set)
vif(fit4) ## less variance
anova(fit2, fit4) ## model 4 over model 2 ## 

summary(fit4) ## Adj. R-squared = 0.4219 ## 
```

```{r with continent, echo=TRUE}
fit5 <- update(fit1, suicides ~ 
                 sex + age +
                 population + continent, train_set)
vif(fit5)
anova(fit4, fit5) ## model 5 over model 4 ## 

summary(fit5) ## Adj. R-squared = 0.4299 ## 
```

Using this linear model generated the RMSE of 691.42, which is better than the RMSE from simply using the mean. 

```{r rmse lm, echo=TRUE}
lm_fit1 <- lm(suicides ~ sex + age + 
               population + continent, train_set)

y_hat1 <- predict(lm_fit1, test_set)

RMSE_lm <- RMSE(actual_suicides, y_hat1)

rmse_results <- bind_rows(rmse_results, 
                          tibble(Method = "Linear Model", 
                       RMSE = RMSE_lm))
rmse_results
```

The figures above suggest that certain variables (i.e., population) might have a different effect on the number of suicides based on the values of another variable (i.e., continent, sex). As such, the possibility of interactions should also be accounted for. 

The nested models approach is likewise used in selecting the linear regression model with interaction terms. 

```{r pop and sex interact, echo=TRUE}
fit6 <- update(fit1, suicides ~ sex + age +  
                 population + continent + population:sex, 
               train_set)
vif(fit6)
anova(fit5, fit6) ## with interactions
summary(fit6) ## adj. r2 = 0.5587
```

```{r pop and age interact, echo=TRUE}
fit7 <- update(fit1, suicides ~ sex + age + 
                 population + continent + population:sex +  
               population:age, train_set)
vif(fit7) ## increased variance with interaction 
anova(fit6, fit7)
summary(fit7) ## adj. r2 = 0.6418
```

```{r pop and generation, echo=TRUE}
fit8 <- update(fit1, suicides ~ sex + age +  
                 population + continent + population:sex +  
                 population:age + population:generation, train_set)
vif(fit8)
anova(fit7, fit8)
summary(fit8) ## adj. r2 = 0.6427
```

```{r pop and continent, echo=TRUE}
fit9 <- update(fit1, suicides ~ sex + age +  
                 population + continent + population:sex +  
                 population:age + population:generation + 
                 population:continent, train_set)
vif(fit9) ## increased variance
anova(fit8, fit9)
summary(fit9) ## adj. r2 = 0.69
```

The linear model which accounts for interactions generated an RMSE of 512.80, which is better than the linear model without interaction terms. 

```{r rmse lm interactions, echo=TRUE}
lm_fit2 <- lm(suicides ~ sex + age + 
                population + continent + 
                population:sex + population:age + 
                population:generation +
                population:continent, 
              train_set)

y_hat2 <- predict(lm_fit2, test_set)

RMSE_lm_int <- RMSE(actual_suicides, y_hat2)

rmse_results <- bind_rows(rmse_results, 
                          tibble(Method = "Linear Model, Interactions", 
                                 RMSE = RMSE_lm_int))
rmse_results
```

# Poisson Regression # 

Since the $Y$ in this case is count data with many zeros, a Poisson regression is a viable option. However, we earlier saw that the variance of the number of suicides is greater than its mean. As such, we should use Quasipoisson regression. 

The quasipoisson model is developed in an analogous manner to how the linear model was developed. In this case, however, the pseudo R-squared values are compared in order to find which quasipoisson model better predicts the outcome. 

```{r quasi sex, echo=TRUE}
glm_fit <- glm(suicides ~ sex, train_set,
               family = "quasipoisson")
summary(glm_fit)
glance(glm_fit) %>% 
  summarize(pseudoR2 = 1 - (deviance/null.deviance)) ## equivalent to R2 ## 
  ## pseudoR2 = 0.0832665
```

```{r quasi plus age, echo=TRUE}
glm_fit <- glm(suicides ~ sex + age, train_set,
               family = "quasipoisson")
summary(glm_fit)
glance(glm_fit) %>% 
  summarize(pseudoR2 = 1 - (deviance/null.deviance)) ## equivalent to R2 ## 
  ## pseudoR2 = 0.229009
```

```{r quasi plus generation, echo=TRUE}
glm_fit <- glm(suicides ~ sex + age + 
                 generation, train_set,
               family = "quasipoisson")
summary(glm_fit)
glance(glm_fit) %>% 
  summarize(pseudoR2 = 1 - (deviance/null.deviance)) ## equivalent to R2 ## 
  ## pseudoR2 = 0.230428
```

```{r quasi plus population, echo=TRUE}
glm_fit <- glm(suicides ~ sex + age + 
                 generation + population, 
               train_set, family = "quasipoisson")
summary(glm_fit)
glance(glm_fit) %>% 
  summarize(pseudoR2 = 1 - (deviance/null.deviance)) ## equivalent to R2 ## 
  ## pseudoR2 = 0.602333
```

```{r quasi plus continent, echo=TRUE}
glm_fit <- glm(suicides ~ sex + age +  
                 generation + population + 
                 continent, train_set, family = "quasipoisson")
summary(glm_fit)
glance(glm_fit) %>% 
  summarize(pseudoR2 = 1 - (deviance/null.deviance)) ## equivalent to R2 ## 
  ## pseudoR2 = 0.602333
```

The quasipoisson model with the continent variable does not improve upon the pseudo R-squared of the model with just the sex, age, generation and population variables. As such, the latter model is the better one and it generates an RMSE of 1110.51. 

```{r rmse quasi, echo=TRUE}
glm_fit <- glm(suicides ~ sex + age +  
                 generation + population + 
                 continent, train_set, 
               family = "quasipoisson")
y_hat3 <- predict(glm_fit, test_set, type = "response")

RMSE_glm <- RMSE(actual_suicides, y_hat3)

rmse_results <- bind_rows(rmse_results, 
                          tibble(Method = "Quasipoisson Model", 
                                 RMSE = RMSE_glm))
rmse_results
```

As with the Linear Model, the Quasipoisson Model might be significantly improved by accounting for interaction terms. As such, interaction terms are added to the model and their respective pseudo R-squared values are compared to identify the best model. 

```{r quasi with interact age, echo=TRUE}
glm_fit <- glm(suicides ~ sex + age +  
                 generation + population + 
                 continent + population:age, 
               train_set, family = "quasipoisson")
summary(glm_fit)
glance(glm_fit) %>% 
  summarize(pseudoR2 = 1 - (deviance/null.deviance)) ## equivalent to R2 ## 
  ## pseudoR2 = 0.791399
```

```{r quasi with interact continent, echo=TRUE}
glm_fit <- glm(suicides ~ sex + age +  
                 generation + population + 
                 continent + population:age + 
                 population:continent, train_set, family = "quasipoisson")
summary(glm_fit)
glance(glm_fit) %>% 
  summarize(pseudoR2 = 1 - (deviance/null.deviance)) ## equivalent to R2 ## 
  ## pseudoR2 = 0.837181 
```

```{r quasi with interact sex, echo=TRUE}
glm_fit <- glm(suicides ~ sex + age +  
                 generation + population + 
                 continent + population:age + 
                 population:continent + population:sex, 
               train_set, family = "quasipoisson")
summary(glm_fit)
glance(glm_fit) %>% 
  summarize(pseudoR2 = 1 - (deviance/null.deviance)) ## equivalent to R2 ## 
  ## pseudoR2 = 0.837947
```

```{r quasi interact with generation, echo=TRUE}
glm_fit <- glm(suicides ~ sex + age +  
                 generation + population + 
                 continent + population:age + 
                 population:continent + population:sex + 
                 population:generation, train_set, family = "quasipoisson")
summary(glm_fit)
glance(glm_fit) %>% 
  summarize(pseudoR2 = 1 - (deviance/null.deviance)) ## equivalent to R2 ## 
  ## pseudoR2 = 0.841450  
```

The final model, with 4 interaction terms, generated the highest pseudo R-squared. This quasipoisson model generated the RMSE of 407, which is a significant improvement from both the first Quasipoisson Model and the Linear Model with Interactions. 

```{r rmse quasi with interactions, echo=TRUE}
glm_fit <- glm(suicides ~ sex + age +  
                 generation + population + 
                 continent + population:age + 
                 population:continent + population:sex + 
                 population:generation, train_set, 
               family = "quasipoisson")
y_hat4 <- predict(glm_fit, test_set, type = "response")

RMSE_glm_int <- RMSE(actual_suicides, y_hat4)

rmse_results <- bind_rows(rmse_results, 
                          tibble(Method = "Quasipoisson Model, Interactions", 
                                 RMSE = RMSE_glm_int))
rmse_results
```

# K-Nearest Neighbors # 

The next model is developed using K-Nearest Neighbors. Under this model, the suicide rate estimates are based on the average of its $k$ closest points. This approach is suitable here, considering that K-Nearest Neighbors is a non-parametric approach which models complex non-linear situations well. 

```{r knn train, echo=TRUE}
set.seed(123, sample.kind = "Rounding")
train_knn <- train(suicides ~ sex + age + generation + 
                     population + continent, 
                   method = "knn",
                   data = train_set,
                   tuneGrid = data.frame(k = seq(1, 51, 2)))

ggplot(train_knn, highlight = TRUE)
train_knn$bestTune ## k = 45
```

The KNN model generated an RMSE of 718.76, which is not better than either the Linear Model with Interactions or the Quasipoisson Model with Interactions. 

```{r knn rmse, echo=TRUE}
y_hat5 <- predict(train_knn, test_set)

RMSE_knn <- RMSE(actual_suicides, y_hat5)

rmse_results <- bind_rows(rmse_results, 
                          tibble(Method = "K-Nearest Neighbors", 
                                 RMSE = RMSE_knn))
rmse_results
```

# Random Forest # 

The final method uses the random forest approach. This approach is a meta-estimator which takes the average of multiple decision trees, thereby improving accuracy without overfitting. 

The first random forest model is developed using the ranger package. This package works well with larger datasets and is faster than the randomForest package. 

```{r rf with ranger, echo=TRUE}
set.seed(123, sample.kind = "Rounding")
fit_rf1 <- ranger(suicides ~ sex + age + generation + 
                    population + continent, 
                  data = train_set,
                    num.trees = 500, 
                  respect.unordered.factors = "order", 
                  seed = 1234)

print(fit_rf1)

y_hat6 <- predict(fit_rf1, test_set)$predictions

RMSE_rf_ranger <- RMSE(actual_suicides, y_hat6)

rmse_results <- bind_rows(rmse_results, 
                          tibble(Method = "Random Forest - Ranger", 
                                 RMSE = RMSE_rf_ranger))
rmse_results
```

The first Random Forest model generated an RMSE of 276.15, which is better than Quasipoisson Model with Interactions and the Linear Model with Interactions. Under this model, the population variable is the most important as it has the highest variable importance value. 

```{r ranger variable importance, echo=TRUE}
fit_rf1$variable.importance 
``` 

The Random Forest model can be tuned in order to generate better results. For example, the mtry value can be optimized. Mtry refers to the number of variables which are selected at each split. 

The randomForest package is used to develop this second tuned Random Forest mode. First, we examine the un-tuned Random Forest model. 

```{r rf randomForest, echo=TRUE}
set.seed(1234, sample.kind = "Rounding")

fit_rf2 <- randomForest(suicides ~ sex + age + generation + 
                          population + continent, 
                        data = train_set, 
                        ntree = 500)
which.min(fit_rf2$mse)
print(fit_rf2)
y_hat7 <- predict(fit_rf2, test_set)

RMSE_rf_1 <- RMSE(actual_suicides, y_hat7)

rmse_results <- bind_rows(rmse_results, 
                          tibble(Method = "Random Forest - Not Tuned", 
                                 RMSE = RMSE_rf_1))
rmse_results
```

This un-tuned Random Forest model generated an RMSE of 543.57, which is higher than that generated by the un-tuned Random Forest - Ranger model. 

Next, the Random Forest model is tuned in order to determine the optimal mtry value. We start with an mtry of 3 (mtryStart), which is increased by a factor of 2 (stepFactor) until the out-of-bag (OOB) error stops improving by 1%. 

```{r mtry tuning, echo=TRUE}
features <- setdiff(names(train_set), "suicides")

set.seed(1234, sample.kind = "Rounding")

mtry <- tuneRF(x = train_set[features],
                 y = train_set$suicides,
                 ntreeTry = 500, 
                 mtryStart = 3, 
                 stepFactor = 2, 
                 improve = 0.01, 
                 trace = FALSE)

best_m <- mtry[mtry[,2] == min(mtry[,2]), 1]
print(mtry)
print(best_m)
```

Here, optimal mtry = 3 as it has the lowest OOB error. Next, we develop the model using the best mtry value. 

```{r best mtry, echo=TRUE}
set.seed(123, sample.kind = "Rounding")
fit_rf3 <- randomForest(suicides ~ sex + age + generation + 
                          population + continent,
                        data = train_set, 
                        mtry = best_m, 
                        importance = TRUE, 
                        ntree = 500)
print(fit_rf3)
```

```{r final prediction, echo=TRUE}
y_hat8 <- predict(fit_rf3, test_set)

RMSE_rf_2 <- RMSE(actual_suicides, y_hat8)

rmse_results <- bind_rows(rmse_results, 
                          tibble(Method = "Random Forest - Tuned", 
                                 RMSE = RMSE_rf_2))
rmse_results
```

The tuned Random Forest model generated the lowest RMSE of 219.90. As with the first Random Forest model, the population variable is the most important in the Tuned Model. 

```{r tuned variable importance, echo=TRUE}
varImpPlot(fit_rf3, main ="Variable Importance")
varImp(fit_rf3)
``` 

### SUMMARY AND CONCLUSIONS ### 

This project aimed to examine global suicide trends using machine learning models in order to determine whether demographic variables were associated with suicide rates. The effectiveness of the models were assessed using the RMSE. 

K-Nearest Neighbors is among the least effective of the approaches, as the KNN model generated a high RMSE. 

We found that linear models did not adequately capture the relationship between suicide rates, on the one hand, and demographic variables on the other. This suggests that the relationship between suicide rates and these variables are non-linear in nature. Nevertheless, the adjusted R-squared values of the linear models improved when (1) the population variable and (2) population's interaction with the other variables were included. 

The Quasipoisson Model with Interactions fared marginally better. However, there seems to still be a significant lack of fit considering the residual deviance of 1,880,745 with 13,877 degrees of freedom. 

The Random Forest:Ranger and Random Forest:Tuned Models performed best, generating an RMSE of 276.15 and 219.90 respectively. These models show that the population variable is the most important, followed by sex. 

This analysis was limited to an exploration of the association between suicide rates and the available demographic variables. The models developed here suggest that suicide rates are associated with population and sex. Specifically, males are more prone to suicides. 

The relationship between population and suicides, however, is more complex, due to the interaction effect of other variables. Thus, this project can be expanded upon by looking into the interaction of population with other, possibly, confounding variables. 
